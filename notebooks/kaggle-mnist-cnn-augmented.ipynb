{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"A deep MNIST classifier using convolutional layers.\n",
    "based on tutorials https://www.tensorflow.org/get_started/mnist/pros\n",
    "and https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist\n",
    "see Legal Notes at the end of the notebook\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import random\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "from tensorflow.contrib.learn.python.learn.datasets import base\n",
    "from tensorflow.contrib.learn.python.learn.datasets.mnist import DataSet\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "SOURCE_URL = 'https://storage.googleapis.com/cloud-deeplearning/kaggle_mnist_data/'\n",
    "DOWNLOAD_DATASETS=True\n",
    "DATA_DIR = '../input/'\n",
    "KAGGLE_TRAIN_CSV = 'train.csv'\n",
    "KAGGLE_TEST_CSV = 'test.csv'\n",
    "SUBMISSION_FILE = 'submission_mnist_cnn_augmented.csv'\n",
    "\n",
    "# should sum up to 42000, the total number of images in train.csv\n",
    "TRAIN_SIZE = 38000\n",
    "VALID_SIZE = 4000\n",
    "TEST_SIZE = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batchnorm(Ylogits, is_test, iteration, offset, convolutional=False):\n",
    "    exp_moving_avg = tf.train.ExponentialMovingAverage(0.999, iteration) # adding the iteration prevents from averaging across non-existing iterations\n",
    "    bnepsilon = 1e-5\n",
    "    if convolutional:\n",
    "        mean, variance = tf.nn.moments(Ylogits, [0, 1, 2])\n",
    "    else:\n",
    "        mean, variance = tf.nn.moments(Ylogits, [0])\n",
    "    update_moving_everages = exp_moving_avg.apply([mean, variance])\n",
    "    m = tf.cond(is_test, lambda: exp_moving_avg.average(mean), lambda: mean)\n",
    "    v = tf.cond(is_test, lambda: exp_moving_avg.average(variance), lambda: variance)\n",
    "    Ybn = tf.nn.batch_normalization(Ylogits, m, v, offset, None, bnepsilon)\n",
    "    return Ybn, update_moving_everages\n",
    "\n",
    "def no_batchnorm(Ylogits, is_test, iteration, offset, convolutional=False):\n",
    "    return Ylogits, tf.no_op()\n",
    "\n",
    "def compatible_convolutional_noise_shape(Y):\n",
    "    noiseshape = tf.shape(Y)\n",
    "    noiseshape = noiseshape * tf.constant([1,0,0,1]) + tf.constant([0,1,1,0])\n",
    "    return noiseshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cnn():\n",
    "    \n",
    "# neural network structure for this sample:\n",
    "#\n",
    "# · · · · · · · · · ·      (input data, 1-deep)                    X [batch, 28, 28, 1]\n",
    "# @ @ @ @ @ @ @ @ @ @   -- conv. layer +BN 6x6x1=>24 stride 1      W1 [5, 5, 1, 24]        B1 [24]\n",
    "# ∶∶∶∶∶∶∶∶∶∶∶∶∶∶∶∶∶∶∶                                              Y1 [batch, 28, 28, 6]\n",
    "#   @ @ @ @ @ @ @ @     -- conv. layer +BN 5x5x6=>48 stride 2      W2 [5, 5, 6, 48]        B2 [48]\n",
    "#   ∶∶∶∶∶∶∶∶∶∶∶∶∶∶∶                                                Y2 [batch, 14, 14, 12]\n",
    "#     @ @ @ @ @ @       -- conv. layer +BN 4x4x12=>64 stride 2     W3 [4, 4, 12, 64]       B3 [64]\n",
    "#     ∶∶∶∶∶∶∶∶∶∶∶                                                  Y3 [batch, 7, 7, 24] => reshaped to YY [batch, 7*7*24]\n",
    "#      \\x/x\\x\\x/ ✞      -- fully connected layer (relu+dropout+BN) W4 [7*7*24, 200]       B4 [200]\n",
    "#       · · · ·                                                    Y4 [batch, 200]\n",
    "#       \\x/x\\x/         -- fully connected layer (softmax)         W5 [200, 10]           B5 [10]\n",
    "#        · · ·                                                     Y [batch, 10]\n",
    "\n",
    "    # three convolutional layers with their channel counts, and a\n",
    "    # fully connected layer (tha last layer has 10 softmax neurons)\n",
    "    K = 24  # first convolutional layer output depth\n",
    "    L = 48  # second convolutional layer output depth\n",
    "    M = 64  # third convolutional layer\n",
    "    N = 200  # fully connected layer\n",
    "\n",
    "    W1 = tf.Variable(tf.truncated_normal([6, 6, 1, K], stddev=0.1))  # 6x6 patch, 1 input channel, K output channels\n",
    "    B1 = tf.Variable(tf.constant(0.1, tf.float32, [K]))\n",
    "    W2 = tf.Variable(tf.truncated_normal([5, 5, K, L], stddev=0.1))\n",
    "    B2 = tf.Variable(tf.constant(0.1, tf.float32, [L]))\n",
    "    W3 = tf.Variable(tf.truncated_normal([4, 4, L, M], stddev=0.1))\n",
    "    B3 = tf.Variable(tf.constant(0.1, tf.float32, [M]))\n",
    "\n",
    "    W4 = tf.Variable(tf.truncated_normal([7 * 7 * M, N], stddev=0.1))\n",
    "    B4 = tf.Variable(tf.constant(0.1, tf.float32, [N]))\n",
    "    W5 = tf.Variable(tf.truncated_normal([N, 10], stddev=0.1))\n",
    "    B5 = tf.Variable(tf.constant(0.1, tf.float32, [10]))\n",
    "\n",
    "    # The model\n",
    "    # batch norm scaling is not useful with relus\n",
    "    # batch norm offsets are used instead of biases\n",
    "    stride = 1  # output is 28x28\n",
    "    Y1l = tf.nn.conv2d(X, W1, strides=[1, stride, stride, 1], padding='SAME')\n",
    "    Y1bn, update_ema1 = batchnorm(Y1l, tst, iter, B1, convolutional=True)\n",
    "    Y1r = tf.nn.relu(Y1bn)\n",
    "    Y1 = tf.nn.dropout(Y1r, pkeep_conv, compatible_convolutional_noise_shape(Y1r))\n",
    "    stride = 2  # output is 14x14\n",
    "    Y2l = tf.nn.conv2d(Y1, W2, strides=[1, stride, stride, 1], padding='SAME')\n",
    "    Y2bn, update_ema2 = batchnorm(Y2l, tst, iter, B2, convolutional=True)\n",
    "    Y2r = tf.nn.relu(Y2bn)\n",
    "    Y2 = tf.nn.dropout(Y2r, pkeep_conv, compatible_convolutional_noise_shape(Y2r))\n",
    "    stride = 2  # output is 7x7\n",
    "    Y3l = tf.nn.conv2d(Y2, W3, strides=[1, stride, stride, 1], padding='SAME')\n",
    "    Y3bn, update_ema3 = batchnorm(Y3l, tst, iter, B3, convolutional=True)\n",
    "    Y3r = tf.nn.relu(Y3bn)\n",
    "    Y3 = tf.nn.dropout(Y3r, pkeep_conv, compatible_convolutional_noise_shape(Y3r))\n",
    "\n",
    "    # reshape the output from the third convolution for the fully connected layer\n",
    "    YY = tf.reshape(Y3, shape=[-1, 7 * 7 * M])\n",
    "\n",
    "    Y4l = tf.matmul(YY, W4)\n",
    "    Y4bn, update_ema4 = batchnorm(Y4l, tst, iter, B4)\n",
    "    Y4r = tf.nn.relu(Y4bn)\n",
    "    Y4 = tf.nn.dropout(Y4r, pkeep)\n",
    "    Ylogits = tf.matmul(Y4, W5) + B5\n",
    "    Y = tf.nn.softmax(Ylogits)\n",
    "    return Y, Ylogits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def custom_kaggle_mnist():\n",
    "    \"\"\"\n",
    "    downloads and parses mnist train dataset for kaggle digit recognizer\n",
    "    parsing and one_hot copied https://www.kaggle.com/kakauandme/tensorflow-deep-nn\n",
    "    \"\"\"\n",
    "    if DOWNLOAD_DATASETS:\n",
    "        base.maybe_download(KAGGLE_TRAIN_CSV, DATA_DIR, SOURCE_URL + KAGGLE_TRAIN_CSV)\n",
    "\n",
    "    # Import data from datasource, see https://www.kaggle.com/kakauandme/tensorflow-deep-nn\n",
    "    # read training data from CSV file \n",
    "    data = pd.read_csv(DATA_DIR + KAGGLE_TRAIN_CSV)\n",
    "    data = shuffle(data, random_state=42)\n",
    "    \n",
    "    images = data.iloc[:,1:].values\n",
    "    images = images.reshape(-1,28,28)\n",
    "    print(images.shape)\n",
    "\n",
    "    augmented_images = augment_images(images[:TRAIN_SIZE])\n",
    "    \n",
    "    print('number of images in downloaded train dataset: {0[0]}'.format(images.shape))\n",
    "    \n",
    "    labels_flat = data.iloc[:,0].values\n",
    "    labels_count = np.unique(labels_flat).shape[0]\n",
    "    def dense_to_one_hot(labels_dense, num_classes):\n",
    "        num_labels = labels_dense.shape[0]\n",
    "        index_offset = np.arange(num_labels) * num_classes\n",
    "        labels_one_hot = np.zeros((num_labels, num_classes))\n",
    "        labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1\n",
    "        return labels_one_hot\n",
    "\n",
    "    labels = dense_to_one_hot(labels_flat, labels_count)\n",
    "    labels = labels.astype(np.uint8)\n",
    "    # for augmented images\n",
    "    labels = np.concatenate((labels, labels))\n",
    "    \n",
    "    # split data into training & validation\n",
    "    mnist_train_images = images[:TRAIN_SIZE]\n",
    "    mnist_train_labels = labels[:TRAIN_SIZE]\n",
    "\n",
    "    # augmentation\n",
    "    mnist_train_images = np.concatenate((np.expand_dims(images[:TRAIN_SIZE], axis=3), augmented_images[:TRAIN_SIZE]))\n",
    "    mnist_train_labels = np.concatenate((labels[:TRAIN_SIZE], labels[:TRAIN_SIZE]))\n",
    "    print('number of all train images: {0[0]}'.format(mnist_train_images.shape))\n",
    "    print('number of augmented train images: {0[0]}'.format(augmented_images.shape))\n",
    "\n",
    "    mnist_valid_images = images[TRAIN_SIZE:TRAIN_SIZE + VALID_SIZE]\n",
    "    mnist_valid_labels = labels[TRAIN_SIZE:TRAIN_SIZE + VALID_SIZE]\n",
    "    mnist_valid_images = np.expand_dims(mnist_valid_images, axis=3)\n",
    "    print('number of valid images: {0[0]}'.format(mnist_valid_images.shape))\n",
    "\n",
    "    mnist_test_images = images[TRAIN_SIZE + VALID_SIZE:TRAIN_SIZE + VALID_SIZE + TEST_SIZE]\n",
    "    mnist_test_labels = labels[TRAIN_SIZE + VALID_SIZE:TRAIN_SIZE + VALID_SIZE + TEST_SIZE]\n",
    "    mnist_test_images = np.expand_dims(mnist_test_images, axis=3)\n",
    "    print('number of test images: {0[0]}'.format(mnist_test_images.shape))\n",
    "    \n",
    "    options = dict(dtype=np.float, reshape=False, seed=42)\n",
    "\n",
    "    train = DataSet(mnist_train_images, mnist_train_labels, options)\n",
    "    valid = DataSet(mnist_valid_images, mnist_valid_labels, options)\n",
    "    test = DataSet(mnist_test_images, mnist_test_labels, options)\n",
    "\n",
    "    return base.Datasets(train=train, validation=valid, test=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def augment_images(images):\n",
    "\n",
    "    augmented_images = np.empty((len(images),28,28,1))\n",
    "\n",
    "    for index in range(len(images)):\n",
    "        if index % 1000 == 0:\n",
    "            print('. {0} images augmented'.format(index))\n",
    "        seq = iaa.Sequential([\n",
    "            iaa.Affine(rotate=random.uniform(15.0,20.0)*random.randint(-1,1)),\n",
    "            iaa.Affine(translate_px=[random.randint(-2,2), random.randint(-2,2)]),\n",
    "            iaa.Affine(shear=random.uniform(10.0,20.0)*random.randint(-1,1)),\n",
    "            iaa.Affine(scale=random.uniform(0.9,1.1)),\n",
    "            iaa.ContrastNormalization(alpha=2),\n",
    "        ])\n",
    "        \n",
    "        augmented_image = seq.augment_images([images[index]])[0]\n",
    "        augmented_images[index] = np.expand_dims(augmented_image, axis=2)\n",
    "        \n",
    "    return augmented_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 28, 28)\n",
      ". 0 images augmented\n",
      ". 1000 images augmented\n",
      ". 2000 images augmented\n",
      ". 3000 images augmented\n",
      ". 4000 images augmented\n",
      ". 5000 images augmented\n",
      ". 6000 images augmented\n",
      ". 7000 images augmented\n",
      ". 8000 images augmented\n",
      ". 9000 images augmented\n",
      ". 10000 images augmented\n",
      ". 11000 images augmented\n",
      ". 12000 images augmented\n",
      ". 13000 images augmented\n",
      ". 14000 images augmented\n",
      ". 15000 images augmented\n",
      ". 16000 images augmented\n",
      ". 17000 images augmented\n",
      ". 18000 images augmented\n",
      ". 19000 images augmented\n",
      ". 20000 images augmented\n",
      ". 21000 images augmented\n",
      ". 22000 images augmented\n",
      ". 23000 images augmented\n",
      ". 24000 images augmented\n",
      ". 25000 images augmented\n",
      ". 26000 images augmented\n",
      ". 27000 images augmented\n",
      ". 28000 images augmented\n",
      ". 29000 images augmented\n",
      ". 30000 images augmented\n",
      ". 31000 images augmented\n",
      ". 32000 images augmented\n",
      ". 33000 images augmented\n",
      ". 34000 images augmented\n",
      ". 35000 images augmented\n",
      ". 36000 images augmented\n",
      ". 37000 images augmented\n",
      "number of images in downloaded train dataset: 42000\n",
      "number of all train images: 76000\n",
      "number of augmented train images: 38000\n",
      "number of valid images: 4000\n",
      "number of test images: 0\n"
     ]
    }
   ],
   "source": [
    "# Import data\n",
    "mnist = custom_kaggle_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def display_digit(image, label, num):\n",
    "    \"\"\"\n",
    "    adapted from https://www.oreilly.com/learning/not-another-mnist-tutorial-with-tensorflow\n",
    "    \"\"\"\n",
    "    image = image.reshape([28,28])\n",
    "    plt.title('Example: %d  Label: %d' % (num, label))\n",
    "    plt.imshow(image, cmap=plt.get_cmap('gray'))\n",
    "    plt.show()\n",
    "\n",
    "def visualize_input(img):\n",
    "    \"\"\"\n",
    "    taken from https://github.com/udacity/aind2-cnn/blob/master/mnist-mlp/mnist_mlp.ipynb\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize = (12,12)) \n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.imshow(img, cmap=plt.get_cmap('gray'))\n",
    "    width, height = img.shape\n",
    "    thresh = img.max()/2.5\n",
    "    for x in range(width):\n",
    "        for y in range(height):\n",
    "            ax.annotate(str(round(img[x][y],2)), xy=(y,x),\n",
    "                        horizontalalignment='center',\n",
    "                        verticalalignment='center',\n",
    "                        color='white' if img[x][y]<thresh else 'black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit_index = random.randint(0, len(mnist.train.images)/2)\n",
    "digit_index_augmented = digit_index + int(len(mnist.train.images)/2)\n",
    "display_digit(mnist.train.images[digit_index], mnist.train.labels[digit_index].argmax(), digit_index)\n",
    "display_digit(mnist.train.images[digit_index_augmented], mnist.train.labels[digit_index_augmented].argmax(), digit_index_augmented)\n",
    "# visualize_input(mnist.train.images[digit_index])\n",
    "# visualize_input(mnist.train.images[digit_index_augmented])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if DOWNLOAD_DATASETS:\n",
    "    kaggle_test_file = base.maybe_download(KAGGLE_TEST_CSV, DATA_DIR, SOURCE_URL + KAGGLE_TEST_CSV)\n",
    "\n",
    "# kaggle test data\n",
    "# test_kaggle = (pd.read_csv(kaggle_test_file).values).astype('float32')\n",
    "test_kaggle = (pd.read_csv(DATA_DIR + KAGGLE_TEST_CSV).values).astype('uint8')\n",
    "test_kaggle = test_kaggle.reshape(-1,28,28)\n",
    "test_kaggle = np.expand_dims(test_kaggle, axis=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input X: 28x28 grayscale images, the first dimension (None) will index the images in the mini-batch\n",
    "X = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "# correct answers will go here\n",
    "Y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "# variable learning rate\n",
    "lr = tf.placeholder(tf.float32)\n",
    "# test flag for batch norm\n",
    "tst = tf.placeholder(tf.bool)\n",
    "iter = tf.placeholder(tf.int32)\n",
    "# dropout probability\n",
    "pkeep = tf.placeholder(tf.float32)\n",
    "pkeep_conv = tf.placeholder(tf.float32)\n",
    "\n",
    "# # Build the graph for the deep net\n",
    "Y, Ylogits = cnn()\n",
    "\n",
    "# cross-entropy loss function (= -sum(Y_i * log(Yi)) ), normalised for batches of 100  images\n",
    "# TensorFlow provides the softmax_cross_entropy_with_logits function to avoid numerical stability\n",
    "# problems with log(0) which is NaN\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=Ylogits, labels=Y_)\n",
    "cross_entropy = tf.reduce_mean(cross_entropy)*batch_size\n",
    "\n",
    "# accuracy of the trained model, between 0 (worst) and 1 (best)\n",
    "correct_prediction = tf.equal(tf.argmax(Y, 1), tf.argmax(Y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# cross_entropy = tf.reduce_mean(\n",
    "#     tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=Y))\n",
    "# train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "# correct_prediction = tf.equal(tf.argmax(Y, 1), tf.argmax(y_, 1))\n",
    "# accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# training step, the learning rate is a placeholder\n",
    "train_step = tf.train.AdamOptimizer(lr).minimize(cross_entropy)\n",
    "\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You can call this function in a loop to train the model, batch_size images at a time\n",
    "def training_step(i, batch_X, batch_Y):\n",
    "\n",
    "    # learning rate decay\n",
    "    max_learning_rate = 0.01\n",
    "    min_learning_rate = 0.0001\n",
    "    decay_speed = 3000\n",
    "    learning_rate = min_learning_rate + (max_learning_rate - min_learning_rate) * math.exp(-i/decay_speed)\n",
    "\n",
    "    # the backpropagation training step\n",
    "    sess.run(train_step, {X: batch_X, Y_: batch_Y, lr: learning_rate, tst: False, pkeep: 0.7, pkeep_conv: 0.7})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(\"Tensorflow version \" + tf.__version__)\n",
    "    tf.set_random_seed(42)\n",
    "    for i in range(15000):\n",
    "        batch_X, batch_Y = mnist.train.next_batch(batch_size)\n",
    "        training_step(i, batch_X, batch_Y)\n",
    "        if i % 200 == 0:\n",
    "            train_accuracy = accuracy.eval(feed_dict={\n",
    "                X: batch_X, Y_: batch_Y, tst: True, pkeep: 1.0, pkeep_conv: 1.0})\n",
    "            validation_accuracy = accuracy.eval(feed_dict={\n",
    "                X: mnist.validation.images, Y_: mnist.validation.labels, tst: True, pkeep: 1.0, pkeep_conv: 1.0})\n",
    "            print('step %d, training accuracy: %g, validation accuracy %g' % (i, train_accuracy, validation_accuracy))\n",
    "\n",
    "    print('validation accuracy %g' % accuracy.eval(feed_dict={\n",
    "            X: mnist.validation.images, Y_: mnist.validation.labels, tst: True, pkeep: 1.0, pkeep_conv: 1.0}))\n",
    "    validation_predictions = sess.run(tf.argmax(Y, 1), feed_dict={X: mnist.validation.images, Y_: mnist.validation.labels, tst: True, pkeep: 1.0, pkeep_conv: 1.0})\n",
    "    validation_labels = sess.run(tf.argmax(mnist.validation.labels, 1))\n",
    "    \n",
    "    prediction_kaggle = tf.argmax(Y, 1)\n",
    "    predictions = []\n",
    "    pred_batch = 100\n",
    "    for i in range(int(len(test_kaggle)/pred_batch)):\n",
    "        feed_dict = {X : test_kaggle[i*pred_batch:(i+1)*pred_batch], tst: True, pkeep: 1.0, pkeep_conv: 1.0}\n",
    "        predictions.extend(sess.run(prediction_kaggle, feed_dict))\n",
    "        if i % 50 == 0:\n",
    "            print('{} images predicted.'.format(i*pred_batch))\n",
    "    print('{} images predicted.'.format(len(test_kaggle)))\n",
    "    \n",
    "# -> validation accuracy 0.987"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_wrong_validation(predictions, valid_labels):\n",
    "  \"\"\"\n",
    "  from http://euler.stat.yale.edu/~tba3/stat665/lectures/lec17/notebook17.html\n",
    "  \"\"\"\n",
    "#   predictions = sess.run(tf.argmax(Y, 1), feed_dict={X: mnist.validation.images, Y_: mnist.validation.labels, tst: True, pkeep: 1.0, pkeep_conv: 1.0})\n",
    "\n",
    "#   valid_labels = sess.run(tf.argmax(mnist.validation.labels, 1))\n",
    "\n",
    "  wrong_valid = [im for im in zip(mnist.validation.images, predictions, valid_labels) if im[1] != im[2]]\n",
    "\n",
    "  print('{0} out of {1} validation images were classified incorrectly'.format(len(wrong_valid), mnist.validation.images.shape[0]))\n",
    "\n",
    "  plt.figure(figsize=(10, 10))\n",
    "  for ind, val in enumerate(wrong_valid[:100]):\n",
    "    plt.subplots_adjust(left=0, right=1, bottom=0, top=1.2)\n",
    "    plt.subplot(10, 10, ind + 1)\n",
    "    im = val[0].reshape((28,28))\n",
    "    plt.axis(\"off\")\n",
    "    plt.text(0, -2, val[2], fontsize=14, color='blue')\n",
    "    plt.text(8, -2, val[1], fontsize=14, color='red')\n",
    "    plt.imshow(im, cmap=plt.get_cmap('gray'))\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "show_wrong_validation(validation_predictions, validation_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result:\n",
    "![Result](./wrong_validation_20170630.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(SUBMISSION_FILE, 'w') as submission:\n",
    "  submission.write('ImageId,Label\\n')\n",
    "  for index, prediction in enumerate(predictions):\n",
    "    submission.write('{0},{1}\\n'.format(index + 1, prediction))\n",
    "  print(\"prediction submission written to {0}\".format(SUBMISSION_FILE))\n",
    "# -> kaggle score of 0.98729"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# developing augmentation\n",
    "\n",
    "# data = pd.read_csv(DATA_DIR + KAGGLE_TRAIN_CSV)\n",
    "# from sklearn.utils import shuffle\n",
    "# data = shuffle(data, random_state=42)\n",
    "# images = data.iloc[:,1:].values    \n",
    "# images = images.reshape(-1,28,28,1)\n",
    "# print(images.shape)\n",
    "# augmented_imgs = augment_images(images[:2])\n",
    "# print(images[:2].shape)\n",
    "# print(augmented_imgs.shape)\n",
    "# print(len(augmented_imgs))\n",
    "# images = np.concatenate((images[:2], augmented_imgs ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train with checkpoint\n",
    "\n",
    "# with tf.Session() as sess:\n",
    "    \n",
    "#     sess.run(tf.global_variables_initializer())\n",
    "#     print(\"Tensorflow version \" + tf.__version__)\n",
    "#     tf.set_random_seed(42)\n",
    "#     for i in range(2000):\n",
    "#         batch_X, batch_Y = mnist.train.next_batch(50)\n",
    "#         training_step(batch_X, batch_Y)\n",
    "#         if i % 200 == 0:\n",
    "#             train_accuracy = accuracy.eval(feed_dict={\n",
    "#                 X: batch_X, Y_: batch_Y, tst: True, pkeep: 1.0, pkeep_conv: 1.0})\n",
    "#             print('step %d, training accuracy %g' % (i, train_accuracy))\n",
    "#     saver.save(sess, './model/cnn.mnist.model.ckpt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predict from checkpoint\n",
    "\n",
    "# with tf.Session() as session:\n",
    "#     session.run(tf.global_variables_initializer())\n",
    "#     saver.restore(session, './model/cnn.mnist.model.ckpt')\n",
    "    \n",
    "#     print('validation accuracy %g' % accuracy.eval(feed_dict={\n",
    "#         X: mnist.validation.images, Y_: mnist.validation.labels, tst: True, pkeep: 1.0, pkeep_conv: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predict from checkpoint\n",
    "\n",
    "# with tf.Session() as session:\n",
    "#     session.run(tf.global_variables_initializer())\n",
    "#     saver.restore(session, './model/cnn.mnist.model.ckpt')\n",
    "\n",
    "#     prediction_kaggle = tf.argmax(Y, 1)\n",
    "#     predictions = []\n",
    "#     pred_batch = 100\n",
    "#     for i in range(int(len(test_kaggle)/pred_batch)):\n",
    "#         feed_dict = {X : test_kaggle[i*pred_batch:(i+1)*pred_batch], tst: True, pkeep: 1.0, pkeep_conv: 1.0}\n",
    "#         predictions.extend(sess.run(prediction_kaggle, feed_dict))\n",
    "#         if i % 50 == 0:\n",
    "#             print('{} images predicted.'.format(i*pred_batch))\n",
    "#     print('{} images predicted.'.format(len(test_kaggle)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Legal Notes:\n",
    "\n",
    "# Copyright and License\n",
    "# from https://github.com/martin-gorner/tensorflow-mnist-tutorial/blob/master/mnist_4.2_batchnorm_convolutional.py\n",
    "\n",
    "# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# =============================================================================="
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "tf35",
   "language": "python",
   "name": "tf35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
