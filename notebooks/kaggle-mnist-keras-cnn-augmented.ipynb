{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using cuDNN version 5110 on context None\n",
      "Mapped name None to device cuda: GeForce GTX 1080 Ti (0000:01:00.0)\n"
     ]
    }
   ],
   "source": [
    "# based on https://www.kaggle.com/jaromiru/keras-cnn-dropout-augmentation-30-min-99-4\n",
    "# sliced validation data from kaggle training set\n",
    "\n",
    "import pandas, numpy, time\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "DATA_DIR = '../input/'\n",
    "KAGGLE_TRAIN_CSV = 'train.csv'\n",
    "KAGGLE_TEST_CSV = 'test.csv'\n",
    "SUBMISSION_FILE = 'submission_mnist_keras_cnn_augmented'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset = namedtuple('Dataset', 'x y')\n",
    "\n",
    "def read_train_valid_test():\n",
    "    data = pandas.read_csv(DATA_DIR + KAGGLE_TRAIN_CSV)\n",
    "    data = shuffle(data, random_state=42)\n",
    "\n",
    "    train_raw = numpy.array(data[:38000])\n",
    "    valid_raw = numpy.array(data[38000:])\n",
    "\n",
    "    train_x = train_raw[:,1:].reshape(train_raw.shape[0], 1, 28, 28).astype('float32') / 255.\n",
    "    train_y = np_utils.to_categorical(train_raw[:,0], 10)\n",
    "\n",
    "    valid_x = valid_raw[:,1:].reshape(valid_raw.shape[0], 1, 28, 28).astype('float32') / 255.\n",
    "    valid_y = np_utils.to_categorical(valid_raw[:,0], 10)\n",
    "\n",
    "    test_raw = numpy.array(pandas.read_csv(DATA_DIR + KAGGLE_TEST_CSV))\n",
    "    test_x = test_raw.reshape(test_raw.shape[0], 1, 28, 28).astype('float32') / 255.\n",
    "\n",
    "    return Dataset(x=train_x, y=train_y), Dataset(x=valid_x, y=valid_y), Dataset(x=test_x, y=None)\n",
    "\n",
    "train, valid, test = read_train_valid_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_1 (Convolution2D)  (None, 32, 24, 24)    832         convolution2d_input_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 32, 12, 12)    0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 32, 10, 10)    9248        maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)    (None, 32, 5, 5)      0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 800)           0           maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 128)           102528      flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 128)           0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 10)            1290        dropout_1[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 113,898\n",
      "Trainable params: 113,898\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_model():\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add( Convolution2D(32, 5, 5, activation='relu', input_shape=(1, 28, 28)) )\n",
    "    model.add( MaxPooling2D() )\n",
    "\n",
    "    model.add( Convolution2D(32, 3, 3, activation='relu') )\n",
    "    model.add( MaxPooling2D() )\n",
    "\n",
    "    model.add( Flatten() ) \n",
    "\n",
    "    model.add( Dense(output_dim=128, activation='relu') )\n",
    "    model.add( Dropout(0.5) )\n",
    "\n",
    "    model.add( Dense(output_dim=10, activation='softmax') )\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        zoom_range=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for step in range(20): # change steps to 20\n",
    "    print('*** Step {0:02d} ***'.format(step+1))\n",
    "    model.fit_generator(datagen.flow(train.x, train.y, batch_size=64),\n",
    "        len(train.x), nb_epoch=10, validation_data=(valid.x,valid.y))\n",
    "\n",
    "    # model.save('model_mnist.h5') # uncomment to save your network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# last epoch:  8s - loss: 0.0245 - acc: 0.9925 - val_loss: 0.0294 - val_acc: 0.9930"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26688/28000 [===========================>..] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "y = model.predict_classes(test.x)\n",
    "filename = SUBMISSION_FILE + \"-\" + time.strftime(\"%Y%m%d%H%M%S\") + '.csv'\n",
    "numpy.savetxt(filename, np.c_[range(1,len(y)+1), y], fmt='%d', delimiter=',', header='ImageId,Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# kaggle score: 0.99443"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf35",
   "language": "python",
   "name": "tf35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
